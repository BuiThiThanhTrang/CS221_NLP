'''
Sample predictive model.
You must supply at least 2 methods:
- fit: trains the model.
- predict: uses the model to perform predictions.
'''
import numpy as np   
import nltk
import re
import html
from nltk import sent_tokenize
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.corpus import wordnet
from nltk.stem import WordNetLemmatizer
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
########## Classifiers
#import xgboost as xgb
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import LinearSVC

#nltk.download('punkt')
#nltk.download("stopwords")
# Táº£i cÃ¡c gÃ³i dá»¯ liá»‡u cáº§n thiáº¿t
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')
nltk.download('wordnet')
nltk.download('omw-1.4')
#nltk.download('punkt_tab')
#nltk.download('averaged_perceptron_tagger_eng')

def get_wordnet_pos(word):
    """
    HÃ m phá»¥ trá»£: Map POS tag cá»§a NLTK sang format cá»§a WordNetLemmatizer
    """
    tag = nltk.pos_tag([word])[0][1][0].upper()
    tag_dict = {"J": wordnet.ADJ,
                "N": wordnet.NOUN,
                "V": wordnet.VERB,
                "R": wordnet.ADV}
    
    # Máº·c Ä‘á»‹nh lÃ  Danh tá»« (NOUN) náº¿u khÃ´ng tÃ¬m tháº¥y
    return tag_dict.get(tag, wordnet.NOUN)

def lemmatize_text(text):
    """
    HÃ m chÃ­nh: Nháº­n vÃ o má»™t cÃ¢u (string) vÃ  tráº£ vá» cÃ¢u Ä‘Ã£ lemmatize (string)
    """
    lemmatizer = WordNetLemmatizer()
    tokens = word_tokenize(text)
    
    result = []
    for word in tokens:
        # Láº¥y tá»« loáº¡i vÃ  lemmatize
        lemma = lemmatizer.lemmatize(word, get_wordnet_pos(word))
        result.append(lemma)
    
    # Ná»‘i láº¡i thÃ nh chuá»—i Ä‘á»ƒ Ä‘Æ°a vÃ o Vectorizer
    return " ".join(result)

def clean_by_majority_vote(x, y):
    """
    Lá»c trÃ¹ng láº·p báº±ng cÃ¡ch giá»¯ láº¡i nhÃ£n xuáº¥t hiá»‡n nhiá»u nháº¥t cho má»—i text.
    """
    df = pd.DataFrame({'text':x, 'label': y})
    counts = df.groupby(['text', 'label']).size().reset_index(name='count')
    counts = counts.sort_values(['text', 'count'], ascending=[True, False])
    
    df_deduped = counts.drop_duplicates(subset=['text'], keep='first')
    return df_deduped[['text', 'label']]

 # ------- model definition --------   
class model1:
  def __init__(self):
    self.classifier = None
    self.vectorizer = None
    
  def preprocess_text(self, text):
    """
    HÃ m lÃ m sáº¡ch tá»«ng dÃ²ng dá»¯ liá»‡u cá»¥ thá»ƒ cho bá»™ data nÃ y
    """
    # 1. QUAN TRá»ŒNG NHáº¤T: Giáº£i mÃ£ HTML entities
    # Dá»¯ liá»‡u cá»§a báº¡n chá»©a: '&#128514;' -> convert thÃ nh 'ðŸ˜‚'
    # Náº¿u khÃ´ng lÃ m bÆ°á»›c nÃ y, mÃ¡y chá»‰ tháº¥y chuá»—i kÃ½ tá»± vÃ´ nghÄ©a.
    text = html.unescape(str(text))
    text = text.replace(":", "").replace("_", " ")

    # 2. Chuyá»ƒn vá» chá»¯ thÆ°á»ng
    text = text.lower()

    # 3. XÃ³a cÃ¡c Mentions vÃ´ nghÄ©a (vÃ­ dá»¥: @T_Madison_x:, @__BrighterDays:)
    # ChÃºng ta khÃ´ng muá»‘n model há»c thuá»™c lÃ²ng tÃªn ngÆ°á»i dÃ¹ng.
    text = re.sub(r'@[A-Za-z0-9_]+:?', '', text)

    # 4. XÃ³a kÃ½ hiá»‡u Retweet (RT) xuáº¥t hiá»‡n dÃ y Ä‘áº·c Ä‘áº§u cÃ¢u
    text = re.sub(r'\brt\b', '', text)

    # 5. XÃ³a URL (náº¿u cÃ³)
    text = re.sub(r'http\S+', '', text)

    # 6. (TÃ¹y chá»n) XÃ³a bá»›t dáº¥u cháº¥m than/há»i dÆ° thá»«a nhÆ°ng giá»¯ láº¡i 1 cÃ¡i
    # !!! -> !
    text = re.sub(r'!+', '!', text)
    text = re.sub(r'\?+', '?', text)

    return text.strip()

  def fit(self, XTrain, YTrain):
    df = clean_by_majority_vote(XTrain, YTrain)
    XTrain = df['text']
    YTrain = df['label']
    XTrain = [self.preprocess_text(x) for x in XTrain]

    print(XTrain)
    self.vectorizer = TfidfVectorizer(
            lowercase=True,
            stop_words='english',
            ngram_range=(1, 2), # DÃ¹ng cá»¥m 1 vÃ  2 tá»«
            min_df=3            # Lá»c nhiá»…u: tá»« pháº£i xuáº¥t hiá»‡n Ã­t nháº¥t 3 láº§n
        )
    vTrain = self.vectorizer.fit_transform(XTrain).toarray()
    self.classifier = LogisticRegression(
            solver='liblinear',
            random_state=42,
            max_iter=1000
            #C=5,              # TÄƒng C
            # !!! QUAN TRá»ŒNG: Xá»­ lÃ½ máº¥t cÃ¢n báº±ng nhÃ£n
            #class_weight='balanced' 
        )
    self.classifier.fit(vTrain, YTrain)

  def predict(self, XTest):	
    vTest = self.vectorizer.transform(XTest).toarray()
    YTest = self.classifier.predict(vTest)
    return YTest

class model:
  def __init__(self):
    self.classifier = None
    self.vectorizer = None

  def preprocess_text(self, text):
    """
    HÃ m lÃ m sáº¡ch tá»«ng dÃ²ng dá»¯ liá»‡u cá»¥ thá»ƒ cho bá»™ data nÃ y
    """
    # 1. QUAN TRá»ŒNG NHáº¤T: Giáº£i mÃ£ HTML entities
    # Dá»¯ liá»‡u cá»§a báº¡n chá»©a: '&#128514;' -> convert thÃ nh 'ðŸ˜‚'
    # Náº¿u khÃ´ng lÃ m bÆ°á»›c nÃ y, mÃ¡y chá»‰ tháº¥y chuá»—i kÃ½ tá»± vÃ´ nghÄ©a.
    text = html.unescape(str(text))
    text = text.replace(":", "").replace("_", " ")
    # 2. Chuyá»ƒn vá» chá»¯ thÆ°á»ng
    text = text.lower()

    # 3. XÃ³a cÃ¡c Mentions vÃ´ nghÄ©a (vÃ­ dá»¥: @T_Madison_x:, @__BrighterDays:)
    # ChÃºng ta khÃ´ng muá»‘n model há»c thuá»™c lÃ²ng tÃªn ngÆ°á»i dÃ¹ng.
    text = re.sub(r'@[A-Za-z0-9_]+:?', '', text)

    # 4. XÃ³a kÃ½ hiá»‡u Retweet (RT) xuáº¥t hiá»‡n dÃ y Ä‘áº·c Ä‘áº§u cÃ¢u
    text = re.sub(r'\brt\b', '', text)

    # 5. XÃ³a URL (náº¿u cÃ³)
    text = re.sub(r'http\S+', '', text)

    # 6. (TÃ¹y chá»n) XÃ³a bá»›t dáº¥u cháº¥m than/há»i dÆ° thá»«a nhÆ°ng giá»¯ láº¡i 1 cÃ¡i
    # !!! -> !
    text = re.sub(r'!+', '!', text)
    text = re.sub(r'\?+', '?', text)

    return text.strip()

  def fit(self, XTrain, YTrain):
    df = clean_by_majority_vote(XTrain, YTrain)
    XTrain = df['text']
    YTrain = df['label']
    XTrain = [self.preprocess_text(x) for x in XTrain]

    self.vectorizer = CountVectorizer()
    vTrain = self.vectorizer.fit_transform(XTrain).toarray()
    #self.classifier = MultinomialNB() 
    #self.classifier = LinearSVC(class_weight='balanced', dual=False) # 0.71
    #self.classifier = xgb.XGBClassifier(n_estimators=100)     # no module
    #self.classifier = RandomForestClassifier(class_weight='balanced', n_jobs=-1)
    self.classifier = LogisticRegression(
      solver='liblinear',
      random_state=42,
      max_iter=1000,
            #C=5,              # TÄƒng C
            # !!! QUAN TRá»ŒNG: Xá»­ lÃ½ máº¥t cÃ¢n báº±ng nhÃ£n
      class_weight='balanced' 
    )
    self.classifier.fit(vTrain, YTrain)


  def predict(self, XTest):	
    vTest = self.vectorizer.transform(XTest).toarray()
    YTest = self.classifier.predict(vTest)
    return YTest
